\documentclass[10pt, letterpaper]{article}

\usepackage[utf8]{inputenc}
\usepackage[none]{hyphenat}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[square, numbers]{natbib}
\usepackage{hyperref}

\hypersetup{
	colorlinks=true,
	linkcolor=magenta,
	urlcolor=cyan,
	citecolor=cyan,
	pdftitle={Matthew Coleman Junior IW Proposal},
	pdfpagemode=FullScreen,
}

\bibliographystyle{abbrvnat}

\title{\vspace{-2em}
	Video Prediction
\vspace{-2em}}
\date{February 16, 2022}

\begin{document}

\maketitle
\begin{center}
	\begin{tabular}{ c c }
		Matthew Coleman 23' & MAE 340
	\end{tabular} \\
	\textbf{Advisor:} Professor Olga Russakovsky
\end{center}

\section{Background}

In many machine learning fields, it is common practice to provide data to a
model in the form of media labeled by large groups of people, for example the
popular ImageNet dataset was put together in part by Amazon's Mechanical Turk
program, a crowdsourcing website that employs thousands of on-demand workers to
contribute to data validation and research tasks. \cite{imagenet}

While this method works well for practical tasks like image classification,
detection, segmentation, etc., datasets collected in such a way naturally
reflect human biases, and this directly drives the training of models that
perpetuate that bias in their real-world implementations. \cite{olga_biases}
Among these human biases are the most egregious: race, gender, sexuality, etc.,
but also the most innocuous, for example in classification tasks, niche,
cultural, or otherwise ``nonconforming" items may be labeled incorrectly or
miscategorized as belonging to a more well-known group. In labeling
segmentation tasks, researchers must make countless ``judgement calls" about
whether something should be considered part of something else or an object in
its own right, and of course, it is notoriously difficult to get thousands of
researchers to agree on one way of doing things. \cite{labeling_disagreement}

The goal of teaching a machine everything about the world---all the while
pretending to know everything about the world---presents a unique challenge. On
one hand, it is desirable and necessary to produce high-classification-accuracy
models to carry out tasks as soon as possible, but on the other hand it is also
wise to seek out machine learning paradigms that don't suffer as much from
human biases, even if they don't yet yield high percentages in classical tasks.

To combat this drawback, some computer vision tasks focus instead on learning
directly from the world, rather than from humans, for example, by using only
real-world observations as ground-truths. An example is the task of video
prediction, in which the goal is to predict a future frame of a video stream
given only the sequence of preceding frames. \cite{video_prediction_survey}
This project will focus on implementing and experimenting on video prediction
tasks with different model architectures.

\section{Research Goals}

The goals for this project are primarily exploratory: to survey video
prediction models by implementing the most notable architectures, experimenting
on different datasets, and making meaningful conclusions from the results.
Also, if applicable, to label and determine sources of bias in models and
datasets used.

\subsection{Datasets}

Datasets may include KTH \cite{kth} (human actions), BAIR
action-free and action-conditioned (robotic pushing movements with and without
robot state), \cite{savp}, and Human 3.6m (human poses and actions)
\cite{humans3_6}, among others.

\subsection{Architectures}

\subsubsection{Convolutional RNN}

A Convolutional RNN is the absolute most basic model architecture capable of
performing video prediction as well as the easiest to implement. Therefore, it
is the natural choice for a baseline model with which to compare proceeding
models on the same datasets.

\subsubsection{LSTM}

An LSTM (Long-Short-Term-Memory) is a modification to the convolutional RNN
which will likely perform better by being able to make use of data over longer
time periods \cite{lstm}, however it is more difficult to implement, and may
suffer from classical video prediction errors such as blurring.

\subsubsection{SAVP}

SAVP (Stochastic Adversarial Video Prediction) is one of the most advanced
methods of video prediction, involving a GAN (Generative Adversarial Network)
as well as a probabilistic model. \cite{savp}

\subsection{Methodology}

Since the plan for this project involves a substantial amount of exploratory
research and experimentation, the best way of accomplishing as much as possible
will be to take an iterative approach: by first exploring a subject mentioned
above, conferring with advisors such as Professor Russakovsky or Professor
Majumdar to help draw meaningful conclusions, and then to choose a branching
direction to continue exploration. In order to make sure that something
substantive is accomplished even if exploration fails, it will be necessary to
code as much as possible so that finished pipelines are completed and results
can be discussed in the final report.

Also, while I plan to implement all aforementioned architectures, it may be
necessary to use researched components either in part or in their entirety for
implementing SAVP, as it is the most difficult architecture to implement.

\section{Timeline}

\begin{center}
	\begin{tabular}{ l l l }
		Week & School Events & Project Todo \\ \hline
		Feb. 14 & & Submit proposal and apply for funds \\
		Feb. 21 & & Research, implement, and test real-world learning methods \\
		Feb. 28 & Midterm Week & \\
		Mar. 7 & Spring Break & \\
		Mar. 14 & & \\
		Mar. 21 & & Design and plan adaptations to learning methods \\
		Mar. 28 & & Implement adaptations and experiment \\
		Apr. 4 & & \\
		Apr. 11 & & \\
		Apr. 18 & Last Week of Classes & Write-up results and make poster \\
		Apr. 25 & & Written Report Deadline (Apr. 26) and Poster Session (Apr. 27)
	\end{tabular} \\
\end{center}

\bibliography{main}

\end{document}
